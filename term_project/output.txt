Linear Regression Results:
Mean Squared Error: 1.5297450693112762
R-squared Score: -0.064923015126509


Linear Regression Coefficients:
X: 0.03862201903194231
Y: 0.05755526613639852
month: 0.14930495049436196
day: 0.025681688190504696
FFMC: 0.008038302041450958
DMC: 0.002391185968400193
DC: -0.0010789750433485082
ISI: -0.027170997713682008
temp: 0.004561485948805679
RH: -0.004913904593814742
wind: 0.04334789926597414
rain: 0.11023679136178241
Bias (Intercept): -0.6981069118864756

Support Vector Regression (SVR) Results:
Mean Squared Error: 1.5830423475938178
R-squared Score: -0.10202560131901395
Bias: -0.3122564957094702


Epoch 1/1000

 1/12 [=>............................] - ETA: 4s - loss: 9352.9990
12/12 [==============================] - 1s 22ms/step - loss: 2316.8008 - val_loss: 701.7942
Epoch 2/1000

 1/12 [=>............................] - ETA: 0s - loss: 974.8384
12/12 [==============================] - 0s 4ms/step - loss: 422.8233 - val_loss: 129.6121
Epoch 3/1000

 1/12 [=>............................] - ETA: 0s - loss: 72.1279
12/12 [==============================] - 0s 3ms/step - loss: 111.6952 - val_loss: 29.9096
Epoch 4/1000

 1/12 [=>............................] - ETA: 0s - loss: 22.0635
12/12 [==============================] - 0s 4ms/step - loss: 33.8077 - val_loss: 16.9203
Epoch 5/1000

 1/12 [=>............................] - ETA: 0s - loss: 32.0588
12/12 [==============================] - 0s 3ms/step - loss: 20.8274 - val_loss: 21.2378
Epoch 6/1000

 1/12 [=>............................] - ETA: 0s - loss: 13.5603
12/12 [==============================] - 0s 4ms/step - loss: 9.4053 - val_loss: 5.3276
Epoch 7/1000

 1/12 [=>............................] - ETA: 0s - loss: 7.2825
12/12 [==============================] - 0s 4ms/step - loss: 4.7669 - val_loss: 3.9813
Epoch 8/1000

 1/12 [=>............................] - ETA: 0s - loss: 3.2125
12/12 [==============================] - 0s 4ms/step - loss: 3.4873 - val_loss: 3.8406
Epoch 9/1000

 1/12 [=>............................] - ETA: 0s - loss: 3.5989
12/12 [==============================] - 0s 4ms/step - loss: 3.1153 - val_loss: 3.8186
Epoch 10/1000

 1/12 [=>............................] - ETA: 0s - loss: 3.8750
12/12 [==============================] - 0s 4ms/step - loss: 3.0920 - val_loss: 3.6702
Epoch 11/1000

 1/12 [=>............................] - ETA: 0s - loss: 2.6545
12/12 [==============================] - 0s 4ms/step - loss: 2.9254 - val_loss: 3.5266
Epoch 12/1000

 1/12 [=>............................] - ETA: 0s - loss: 4.2662
12/12 [==============================] - 0s 3ms/step - loss: 2.8321 - val_loss: 3.5334
Epoch 13/1000

 1/12 [=>............................] - ETA: 0s - loss: 3.4562
12/12 [==============================] - 0s 4ms/step - loss: 2.8417 - val_loss: 3.4846
Epoch 14/1000

 1/12 [=>............................] - ETA: 0s - loss: 2.7414
12/12 [==============================] - 0s 4ms/step - loss: 2.7298 - val_loss: 3.4833
Epoch 15/1000

 1/12 [=>............................] - ETA: 0s - loss: 2.3550
12/12 [==============================] - 0s 4ms/step - loss: 2.7145 - val_loss: 3.3277
Epoch 16/1000

 1/12 [=>............................] - ETA: 0s - loss: 2.1874
12/12 [==============================] - 0s 4ms/step - loss: 2.7055 - val_loss: 3.3574
Epoch 17/1000

 1/12 [=>............................] - ETA: 0s - loss: 1.7673
12/12 [==============================] - 0s 3ms/step - loss: 2.7179 - val_loss: 3.4461
Epoch 18/1000

 1/12 [=>............................] - ETA: 0s - loss: 2.3573
12/12 [==============================] - 0s 3ms/step - loss: 2.8623 - val_loss: 3.5877
Epoch 19/1000

 1/12 [=>............................] - ETA: 0s - loss: 3.1427
12/12 [==============================] - 0s 4ms/step - loss: 2.7437 - val_loss: 3.6376

1/4 [======>.......................] - ETA: 0s
4/4 [==============================] - 0s 1000us/step
Neural Network Results:
Mean Squared Error: 1.8223147226524434
R-squared Score: -0.2685936551703867
Bias: 0.2124133637788371


Neural Network Weights:
Layer 1:
[[-2.7149621e-02 -7.6305613e-02  7.8585297e-02 ...  9.8964192e-02
  -2.9890062e-03 -1.3863362e-01]
 [ 1.5789909e-02  8.2972832e-02 -1.6865507e-01 ...  9.3421504e-02
   6.8995133e-03  2.0772664e-01]
 [-2.6330570e-06 -3.6554310e-02  7.3855259e-02 ...  1.7243508e-01
   5.8947477e-02  9.5037386e-02]
 ...
 [-1.4830987e-02  9.2307732e-02 -1.2266707e-01 ...  1.6066819e-01
   1.0737139e-03  1.4852516e-01]
 [ 1.3665772e-06 -2.1775650e-02  1.4955401e-01 ... -1.6298996e-01
   2.8622832e-02 -1.6482757e-01]
 [ 3.7090324e-08 -2.5332611e-02 -1.6918330e-01 ... -1.0564318e-01
   2.5371868e-05 -1.7109102e-01]]
Layer 2:
[ 0.         -0.01247531  0.0074073   0.00542933 -0.01054918  0.00075265
  0.          0.         -0.00812671 -0.00967236  0.         -0.01099268
  0.00674804 -0.00630317  0.00932648 -0.01808111 -0.00982994 -0.01147067
  0.01509686 -0.0081937  -0.00361533  0.00257364  0.          0.
 -0.0051868   0.          0.00613979  0.00010877  0.00544149 -0.00911093
  0.00106506  0.         -0.0119338   0.         -0.00530002  0.00583419
 -0.01034887  0.         -0.00932491 -0.00432788  0.0026102  -0.00873763
  0.00377535 -0.01405271  0.00986742 -0.01339669  0.00727579  0.04496358
 -0.00540396 -0.01870154  0.00523963  0.00503741 -0.00332728  0.00331945
  0.         -0.0105957  -0.01008782 -0.00935355 -0.00529494 -0.00941105
  0.00544897  0.00028261 -0.00859917 -0.00754315  0.0057036  -0.00270546
 -0.00817718  0.00707722  0.00841769  0.         -0.01009768  0.0066769
 -0.0039153   0.01860731  0.         -0.00912841 -0.00225913  0.00569355
 -0.00992262 -0.02124497  0.         -0.00718696 -0.01805723  0.
 -0.00600456 -0.00461944  0.          0.         -0.01109983 -0.01025834
  0.00145896  0.00415416  0.00341325 -0.00511423  0.00469251 -0.00766279
 -0.00582436  0.01002044 -0.01027226 -0.00581035 -0.00684122 -0.01374721
  0.01759945 -0.00810773 -0.01779924 -0.00864671  0.         -0.0114113
  0.          0.01105452  0.00206528  0.01691207  0.01292107  0.00297415
  0.01618864 -0.00968138  0.00343135 -0.00687743 -0.00226369 -0.00340162
  0.0029548   0.00899609 -0.00858271  0.0026398  -0.01779363 -0.01317186
  0.          0.00338314]
Layer 3:
[[ 1.09999246e-05 -1.54836029e-02 -1.74258759e-08 ...  3.62485275e-02
   2.64976006e-06  2.85899397e-02]
 [ 1.05730452e-01  2.65785530e-02  1.30402252e-01 ... -6.02058284e-02
  -3.89180183e-02 -8.49981370e-06]
 [-1.13649160e-01 -1.37793515e-02  1.22442760e-01 ... -7.67793432e-02
  -2.90555470e-02 -2.23885085e-02]
 ...
 [ 1.50979787e-01  6.46579638e-02 -1.41889885e-01 ...  1.55978963e-01
  -2.45755520e-02  6.15398074e-03]
 [-2.16558054e-02 -3.88767309e-02  3.86684872e-02 ...  3.56852581e-07
  -1.90237991e-03 -3.97451222e-02]
 [-1.43298805e-01 -2.93815155e-02 -2.50520688e-02 ...  6.20977357e-02
   9.44953132e-03 -3.75012052e-04]]
Layer 4:
[ 0.00112681 -0.00873946  0.00652446 -0.00941059  0.         -0.00737609
  0.          0.00696599 -0.00863472 -0.00744425 -0.00555887 -0.00776441
 -0.00476937 -0.01276629 -0.0087523   0.          0.          0.
 -0.00781525 -0.00202366 -0.00730015 -0.0054403  -0.00373    -0.00465775
 -0.00102327  0.0051113  -0.00367909 -0.00600547 -0.00418529  0.
 -0.00738105 -0.0035853  -0.00750041 -0.00600547  0.          0.
 -0.00766297 -0.0038876   0.0069115  -0.01181495  0.         -0.00761972
  0.00693963 -0.00528011 -0.00294026  0.         -0.01080566 -0.0076373
 -0.00541044  0.00693452  0.         -0.01075673 -0.00336879  0.00207041
  0.         -0.0057815  -0.00766294 -0.01211562 -0.00555636 -0.00603778
 -0.00274274 -0.01203488  0.         -0.00900265]
Layer 5:
[[ 0.26642206]
 [-0.20946987]
 [ 0.06472671]
 [-0.11732713]
 [ 0.17749116]
 [-0.1415473 ]
 [ 0.0753659 ]
 [ 0.24897785]
 [-0.06953403]
 [-0.12516508]
 [-0.20673887]
 [-0.06926376]
 [-0.22179995]
 [-0.15080935]
 [-0.0128769 ]
 [-0.06181942]
 [-0.13276948]
 [ 0.17203376]
 [-0.16943729]
 [ 0.28727108]
 [-0.28560096]
 [-0.01232922]
 [-0.07414709]
 [ 0.22154051]
 [ 0.1035048 ]
 [ 0.18825145]
 [-0.08223117]
 [-0.2848673 ]
 [ 0.09445821]
 [-0.27047887]
 [-0.14465186]
 [-0.2117162 ]
 [-0.10896784]
 [-0.2701619 ]
 [-0.07260381]
 [-0.21283427]
 [-0.07421236]
 [ 0.24480006]
 [ 0.1959022 ]
 [-0.19893596]
 [ 0.11672756]
 [-0.24937898]
 [ 0.23083428]
 [-0.29365602]
 [ 0.08665704]
 [ 0.00944582]
 [-0.26796404]
 [-0.06426433]
 [-0.02680825]
 [ 0.17233473]
 [-0.2701019 ]
 [-0.1876421 ]
 [ 0.17942797]
 [ 0.14666845]
 [ 0.03667718]
 [ 0.26027834]
 [-0.25978324]
 [-0.10000453]
 [-0.05041942]
 [-0.22778478]
 [ 0.28754252]
 [-0.21898586]
 [ 0.07990485]
 [ 0.11126011]]
Layer 6:
[0.00719528]
RF Results:
Mean Squared Error: 1.8280765056207182
R-squared Score: -0.2726046864292371
Bias: 0.3890444423530942
Summary of Results:
Linear Regression R-squared Score: 0.064923015126509
SVR R-squared Score: 0.10202560131901395
Random Forest R-squared Score: 0.2726046864292371
Neural Network R-squared Score: 0.2685936551703867
Linear Regression Mean Squared Error: 1.5297450693112762
SVR Mean Squared Error: 1.5830423475938178
Random Forest Mean Squared Error: 1.8280765056207182
Neural Network Mean Squared Error: 1.8223147226524434
Linear Regression Bias: -0.6981069118864756
SVR Bias: -0.3122564957094702
Random Forest Bias: 0.3890444423530942
Neural Network Bias: 0.2124133637788371
